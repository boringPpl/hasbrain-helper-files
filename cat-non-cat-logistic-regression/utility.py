import numpy as np
import h5py

def load_dataset():
    '''
    Load dataset from h5 file to numpy array
    Returns:
    - A tuple: (training data array, training label array, test data array, test label array, number of class)
    '''
    train_dataset = h5py.File('input/catnnoncat/cat_n_noncat/train_catvnoncat.h5', "r")
    train_set_x_orig = np.array(train_dataset["train_set_x"][:]) # your train set features
    train_set_y_orig = np.array(train_dataset["train_set_y"][:]) # your train set labels

    test_dataset = h5py.File('input/catnnoncat/cat_n_noncat/test_catvnoncat.h5', "r")
    test_set_x_orig = np.array(test_dataset["test_set_x"][:]) # your test set features
    test_set_y_orig = np.array(test_dataset["test_set_y"][:]) # your test set labels

    classes = np.array(test_dataset["list_classes"][:]) # the list of classes

    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))
    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))

    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes

def load_standardlized_dataset():
    '''
    Load the dataset and preprocess it
    Returns:
    - A tuple: (standardlized training data array, training label array, standardlized test data array, test label array, number of class)
    '''
    train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()
    train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T
    test_set_x_flatten =  test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T
    train_set_x = train_set_x_flatten/255.
    test_set_x = test_set_x_flatten/255.
    return train_set_x, train_set_y, test_set_x, test_set_y, classes

def initialize_with_zeros(dim):
    """
    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.

    Argument:
    dim -- size of the w vector we want (or number of parameters in this case)

    Returns:
    w -- initialized vector of shape (dim, 1)
    b -- initialized scalar (corresponds to the bias)
    """

    ### START CODE HERE ### (≈ 1 line of code)
    w = np.zeros((dim,1))
    b = 0.0
    ### END CODE HERE ###

    assert(w.shape == (dim, 1))
    assert(isinstance(b, float) or isinstance(b, int))

    return w, b

def sigmoid(z):
    """
    Compute the sigmoid of z

    Arguments:
    z -- A scalar or numpy array of any size.

    Return:
    s -- sigmoid(z)
    """

    return 1/(1+np.exp(-z))

def propagate(w, b, X, Y):
    """
    Implement the cost function and its gradient for the propagation explained above

    Arguments:
    w -- weights, a numpy array of size (num_px * num_px * 3, 1)
    b -- bias, a scalar
    X -- data of size (num_px * num_px * 3, number of examples)
    Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)

    Return:
    cost -- negative log-likelihood cost for logistic regression
    dw -- gradient of the loss with respect to w, thus same shape as w
    db -- gradient of the loss with respect to b, thus same shape as b

    Tips:
    - Write your code step by step for the propagation. np.log(), np.dot()
    """

    m = X.shape[1]
    # FORWARD PROPAGATION (FROM X TO COST)
    ### START CODE HERE ### (≈ 2 lines of code)
    A = sigmoid(np.dot(w.T,X)+b) # compute activation
    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A))) # compute cost
    ### END CODE HERE ###

    # BACKWARD PROPAGATION (TO FIND GRAD)
    ### START CODE HERE ### (≈ 2 lines of code)
    dz= (1/m)*(A - Y)
    dw = np.dot(X,dz.T) # gradient of w
    db = np.sum(dz) # gradient of bias
    ### END CODE HERE ###

    assert(dw.shape == w.shape)
    assert(db.dtype == float)
    cost = np.squeeze(cost)
    assert(cost.shape == ())

    grads = {"dw": dw,
             "db": db}

    return grads, cost

def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):
    """
    This function optimizes w and b by running a gradient descent algorithm

    Arguments:
    w -- weights, a numpy array of size (num_px * num_px * 3, 1)
    b -- bias, a scalar
    X -- data of shape (num_px * num_px * 3, number of examples)
    Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)
    num_iterations -- number of iterations of the optimization loop
    learning_rate -- learning rate of the gradient descent update rule
    print_cost -- True to print the loss every 100 steps

    Returns:
    params -- dictionary containing the weights w and bias b
    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function
    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.

    Tips:
    You basically need to write down two steps and iterate through them:
        1) Calculate the cost and the gradient for the current parameters. Use propagate().
        2) Update the parameters using gradient descent rule for w and b.
    """

    costs = []

    for i in range(num_iterations):


        # Cost and gradient calculation (≈ 1-4 lines of code)
        ### START CODE HERE ###
        grads, cost = propagate(w, b, X, Y)
        ### END CODE HERE ###

        # Retrieve derivatives from grads
        dw = grads["dw"]
        db = grads["db"]

        # update rule (≈ 2 lines of code)
        ### START CODE HERE ###
        w -= (learning_rate*dw)
        b -= (learning_rate*db)
        ### END CODE HERE ###

        # Record the costs
        if i % 100 == 0:
            costs.append(cost)

        # Print the cost every 100 training examples
        if print_cost and i % 100 == 0:
            print ("Cost after iteration %i: %f" %(i, cost))

    params = {"w": w,
              "b": b}

    grads = {"dw": dw,
             "db": db}

    return params, grads, costs

def predict(w, b, X):
    '''
    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)

    Arguments:
    w -- weights, a numpy array of size (num_px * num_px * 3, 1)
    b -- bias, a scalar
    X -- data of size (num_px * num_px * 3, number of examples)

    Returns:
    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X
    '''

    m = X.shape[1]
    Y_prediction = np.zeros((1,m))
    w = w.reshape(X.shape[0], 1)

    # Compute vector "A" predicting the probabilities of a cat being present in the picture
    ### START CODE HERE ### (≈ 1 line of code)
    A =  sigmoid(np.dot(w.T,X)+ b)

    ### END CODE HERE ###
    for i in range(A.shape[1]):

        # Convert probabilities A[0,i] to actual predictions p[0,i]
        ### START CODE HERE ### (≈ 1 line1 of code)
        Y_prediction = 1. * (A > 0.5)
        ### END CODE HERE ###

    assert(Y_prediction.shape == (1, m))

    return Y_prediction

def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):
    """
    Builds the logistic regression model by calling the function you've implemented previously

    Arguments:
    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)
    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)
    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)
    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)
    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters
    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()
    print_cost -- Set to true to print the cost every 100 iterations

    Returns:
    d -- dictionary containing information about the model.
    """

    ### START CODE HERE ###

    # initialize parameters with zeros (≈ 1 line of code)
    w, b = initialize_with_zeros(X_train.shape[0])

    # Gradient descent (≈ 1 line of code)
    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = print_cost)

    # Retrieve parameters w and b from dictionary "parameters"
    w = parameters["w"]
    b = parameters["b"]

    # Predict test/train set examples (≈ 2 lines of code)
    Y_prediction_test = predict(w,b,X_test)
    Y_prediction_train = predict(w,b,X_train)

    ### END CODE HERE ###

    # Print train/test Errors
    print("train accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))
    print("test accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))


    d = {"costs": costs,
         "Y_prediction_test": Y_prediction_test,
         "Y_prediction_train" : Y_prediction_train,
         "w" : w,
         "b" : b,
         "learning_rate" : learning_rate,
         "num_iterations": num_iterations}

    return d

def test_sigmoid():
    test_inputs = [
        np.array([[1,2],[3,4]]),
        np.array([[-1,3],[13,4],[0,1]]),
        np.array([3,4,5]),
        np.array([[1,2,3,4],[3,4,5,6]]),
        np.array([3,4]),
        np.array([[1,2],[13,41],[23,45],[113,24]]),
        np.array([3,4,0,0]),
        np.array([[1,2,2],[3,4,2]]),
        np.array([13,24])
    ]

    expected_outputs = [
        np.array([[ 0.73105858,  0.88079708],
           [ 0.95257413,  0.98201379]]),
        np.array([[ 0.26894142,  0.95257413],
           [ 0.99999774,  0.98201379],
           [ 0.5       ,  0.73105858]]),
        np.array([ 0.95257413,  0.98201379,  0.99330715]),
        np.array([[ 0.73105858,  0.88079708,  0.95257413,  0.98201379],
           [ 0.95257413,  0.98201379,  0.99330715,  0.99752738]]),
        np.array([ 0.95257413,  0.98201379]),
        np.array([[ 0.73105858,  0.88079708],
           [ 0.99999774,  1.        ],
           [ 1.        ,  1.        ],
           [ 1.        ,  1.        ]]),
        np.array([ 0.95257413,  0.98201379,  0.5       ,  0.5       ]),
        np.array([[ 0.73105858,  0.88079708,  0.88079708],
           [ 0.95257413,  0.98201379,  0.88079708]]),
        np.array([ 0.99999774,  1.        ])
    ]
    return test_inputs, expected_outputs

def test_propagate():
    test_inputs = [(np.array([[ 0.86717585],
             [ 8.03493734],
             [ 0.90865739],
             [ 2.71325554],
             [ 3.86952413]]),
      8.924302608161739,
      np.array([[ 2.66729666,  0.83826951,  0.29246205,  2.14415924,  1.20234782,
               2.47033784,  1.81460282,  0.11265537,  1.81984952,  2.05505664,
               0.0196817 ,  0.83917525],
             [ 0.52867772,  1.4634736 ,  0.08915141,  1.18414587,  0.72771719,
               2.43476818,  1.53290755,  0.217224  ,  2.27213239,  0.06290109,
               0.04528394,  2.57898919],
             [ 2.6307514 ,  1.49545031,  0.5792385 ,  2.12036343,  1.17591302,
               0.42129971,  0.56339094,  0.86532054,  0.72177407,  1.97292419,
               0.83485538,  1.08703999],
             [ 1.69209656,  2.72318919,  2.48538839,  2.97032829,  0.06787846,
               1.037024  ,  1.97725399,  1.03979296,  2.61054339,  0.47312643,
               0.32169324,  1.38396588],
             [ 2.0940399 ,  1.30867842,  1.70374316,  1.32904259,  2.91124343,
               0.07347759,  2.60358661,  0.69371092,  1.4025634 ,  2.32338829,
               2.91088906,  0.91579748]]),
      np.array([[ 1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.]])),
     (np.array([[ 3.26560029]]),
      3.3783266024307217,
      np.array([[ 0.68028634,  0.47536644,  0.40820536,  0.5065777 ,  0.57677893,
               0.19296128,  0.0373546 ,  0.33223841,  0.78571688,  0.20086868,
               0.56641124,  0.02091999,  0.28895048,  0.05505587,  0.39339425,
               0.21732227,  0.87787964,  0.03211217,  0.53581854]]),
      np.array([[ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,
               1.,  1.,  1.,  1.,  1.,  1.]])),
     (np.array([[ 0.00982413]]),
      -2.5909427897577775,
      np.array([[ 3.25532949]]),
      np.array([[ 0.]])),
     (np.array([[ 2.49231187],
             [ 0.90261213],
             [ 3.73288738]]),
      6.879230337539482,
      np.array([[ 1.60049388,  1.35856355,  1.09958807,  0.48805953,  1.05636965,
               1.58292311,  1.32585452,  1.73855007,  2.54925412,  2.6681989 ,
               2.74368903,  0.16750145,  1.02545294,  2.97664947,  0.59227403,
               1.12936141,  1.27880765],
             [ 0.68054027,  2.22125073,  1.28793262,  0.31770443,  0.86349656,
               0.74482615,  1.69306061,  0.10887424,  2.28939018,  1.22369602,
               2.73761527,  1.67793944,  0.63579084,  0.31465301,  0.43075468,
               1.07400719,  0.21840702],
             [ 2.28426603,  2.54428189,  0.97709985,  0.83146731,  0.71600713,
               2.12958795,  2.60108188,  2.19336796,  1.5935891 ,  1.31059168,
               1.87714577,  0.70445022,  2.29815875,  2.93145966,  2.45851518,
               0.57996003,  1.62175868]]),
      np.array([[ 1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  1.]])),
     (np.array([[ 0.23744389],
             [ 2.66923162]]),
      0.15854451684232096,
      np.array([[ 1.04648488,  2.83687014,  0.22091381,  4.87790512,  5.15138752,
               0.7623651 ,  0.11090703,  3.08557977,  3.18882192,  1.1112289 ,
               5.59462467],
             [ 4.70458985,  4.85266623,  1.42744135,  4.9396991 ,  0.01198469,
               5.49654058,  3.49356221,  1.8350681 ,  4.28425689,  4.39260002,
               4.6053759 ]]),
      np.array([[ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.]])),
     (np.array([[ 4.84662271],
             [ 2.48604917]]),
      -8.607346714961416,
      np.array([[ 2.21004028,  5.10231191,  4.93713962,  4.72965614,  6.75687196,
               2.60154637,  6.94972798,  4.77785717,  7.324282  ],
             [ 7.14725998,  3.19357702,  2.56474119,  3.31848722,  1.31536751,
               6.98803349,  5.37540606,  7.44773347,  4.89270677]]),
      np.array([[ 1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.]])),
     (np.array([[ 8.75644456],
             [ 9.14843089]]),
      2.397410585436827,
      np.array([[ 6.81024044,  5.41804509,  1.67016704,  5.41130823,  2.96066901,
               0.31961368,  3.25887757,  5.20149228,  2.42444693,  6.40809972,
               3.85142825,  3.38896917,  6.27081124,  0.54018931,  7.77462336,
               0.20655481,  6.59012767,  2.10773391],
             [ 3.11245739,  6.81728192,  6.8847784 ,  4.06958545,  7.2858601 ,
               3.55160359,  6.23868471,  7.86139836,  6.52003233,  1.6038633 ,
               3.75786396,  2.16325085,  1.38427699,  7.92234283,  2.08013187,
               7.07748777,  4.50559412,  1.26461614]]),
      np.array([[ 1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,
               1.,  0.,  1.,  1.,  1.]])),
     (np.array([[ 0.237812  ],
             [ 0.47359954],
             [ 0.53421666],
             [ 0.82710381]]),
      -5.3756707064322296,
      np.array([[  1.59791399e+00,   6.37825747e-01,   2.85594493e+00,
                2.46204561e+00,   1.78987374e+00,   1.66875099e+00,
                1.41149750e+00,   2.36269333e+00,   1.94707628e+00,
                3.04257604e+00,   2.49490971e+00,   1.42775261e+00,
                2.49810759e+00,   1.91613357e+00,   3.29768177e+00,
                3.89281796e+00,   3.69681024e+00,   3.40717706e+00],
             [  2.22453752e+00,   1.47984880e+00,   3.75223266e+00,
                2.49445942e+00,   2.74521949e+00,   1.18723384e+00,
                1.08173190e+00,   1.26213080e+00,   2.89933870e+00,
                1.90016776e+00,   6.64737600e-01,   2.53003764e+00,
                3.32649333e+00,   2.47883367e+00,   3.55503287e+00,
                1.42749880e+00,   3.05299614e+00,   4.73000377e-02],
             [  8.81305024e-01,   2.19785062e+00,   2.36021397e+00,
                1.85779941e+00,   8.71930025e-01,   1.53769225e+00,
                2.74720042e+00,   3.71535441e+00,   1.75682737e+00,
                2.74964386e-01,   1.91655520e+00,   1.82176121e+00,
                9.40453179e-01,   3.18641157e+00,   2.37124999e-01,
                2.69434178e+00,   2.31348538e+00,   2.78730624e+00],
             [  2.92004599e+00,   4.32224952e-01,   2.47646863e+00,
                2.26249789e+00,   1.05262474e+00,   1.94222117e+00,
                1.29825936e+00,   3.39836963e+00,   2.68113351e+00,
                1.31794528e+00,   1.84633902e-01,   1.45277953e+00,
                2.65309977e-03,   1.33222884e+00,   1.60016935e+00,
                3.90057592e+00,   1.92725145e+00,   2.72848285e+00]]),
      np.array([[ 1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  1.,  0.]])),
     (np.array([[ 0.06595244]]),
      -1.626250650032702,
      np.array([[ 3.88095858,  1.81523379,  2.38225712,  2.8583802 ,  4.03066063,
               4.54360876,  4.2609518 ,  4.1248972 ,  4.97568098,  3.28747156,
               3.26847053,  0.99203543,  0.78529315,  4.9337328 ,  3.7010071 ,
               2.78608978,  0.48100978,  1.86722364]]),
      np.array([[ 0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,
               1.,  0.,  1.,  0.,  1.]])),
     (np.array([[ 1.67359335],
             [ 3.81840948],
             [ 2.31151092],
             [ 2.64249795],
             [ 2.92031828]]),
      -4.044331483025044,
      np.array([[ 2.45730491,  2.08999512,  2.98199899,  1.10589914,  2.36570174,
               2.48310503,  2.25051025,  2.52304526,  1.75041695,  2.61420418,
               1.54152094,  1.09168475,  2.9308714 ,  2.89430337,  2.69899214,
               2.4951992 ,  2.35106091,  0.14681582,  0.93683875,  1.47020719],
             [ 1.74292765,  1.17371972,  2.58027861,  2.93959637,  0.98434858,
               2.41175479,  0.78941665,  1.28911166,  1.08542725,  0.22049081,
               0.04797752,  1.28558864,  2.74508142,  1.83192667,  0.2703349 ,
               2.03254133,  0.09261064,  1.14475657,  1.03536031,  2.77151228],
             [ 1.58014649,  1.27121889,  2.32628094,  2.67320958,  2.98203263,
               0.00468814,  2.3613562 ,  2.88491127,  0.20357247,  2.37189924,
               1.47352383,  2.45351589,  0.4472298 ,  1.71661337,  1.97040473,
               0.21422595,  1.96110022,  0.80898681,  0.06142602,  1.92341402],
             [ 1.45878515,  1.90567354,  1.48924623,  0.87130262,  2.54565189,
               2.03957961,  0.71434625,  1.50204531,  0.82328648,  2.09859867,
               1.55920215,  2.94957463,  2.88189807,  1.47067746,  2.86593025,
               0.12391454,  1.8831459 ,  0.73112402,  0.40081428,  2.41311476],
             [ 2.54676834,  1.18955766,  1.03594131,  1.33828681,  2.13537721,
               0.09885109,  0.8478826 ,  2.86329287,  0.68707373,  1.84998644,
               1.0181972 ,  0.87801463,  0.80328565,  1.20000673,  1.41965514,
               2.05548203,  2.51318858,  2.61116241,  0.48835568,  0.05539466]]),
      np.array([[ 0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  0.,  1.,  1.,  1.]]))]

    expected_outputs = [({'dw': np.array([[ 0.25490796],
              [ 0.36818934],
              [ 0.25791583],
              [ 0.57386676],
              [ 0.49306984]]), 'db': 0.33333333005217552}, np.nan),
     ({'dw': np.array([[ 0.12186375]]), 'db': 0.30260940313119344},
      1.4870050814008973),
     ({'dw': np.array([[ 0.23381961]]), 'db': 0.071826711788208375},
      0.074536830641526081),
     ({'dw': np.array([[ 0.64945926],
              [ 0.57467283],
              [ 0.80446557]]), 'db': 0.47058666431907953}, 8.3776352569100911),
     ({'dw': np.array([[ 1.32906768],
              [ 1.87055957]]), 'db': 0.61669031086140103}, 5.4612742301395656),
     ({'dw': np.array([[ 2.35572499],
              [ 1.62736993]]), 'db': 0.44444444406262484}, np.nan),
     ({'dw': np.array([[ 1.75603699],
              [ 2.21933682]]), 'db': 0.44444444444444398}, np.nan),
     ({'dw': np.array([[-0.14119197],
              [-0.20677008],
              [-0.20738074],
              [ 0.00735983]]), 'db': -0.11841725252853359}, 0.87335421016624126),
     ({'dw': np.array([[-1.1466664]]), 'db': -0.30570409821459804},
      0.9132917389104569),
     ({'dw': np.array([[ 1.20304171],
              [ 0.65552989],
              [ 0.87884019],
              [ 1.00976849],
              [ 0.82094456]]), 'db': 0.49915977034930292}, 9.5993034994555995)]
    return test_inputs, expected_outputs

def test_optimize():
    test_inputs = [(np.array([[ 0.86717585],
             [ 8.03493734],
             [ 0.90865739],
             [ 2.71325554],
             [ 3.86952413]]),
      8.924302608161739,
      np.array([[ 2.66729666,  0.83826951,  0.29246205,  2.14415924,  1.20234782,
               2.47033784,  1.81460282,  0.11265537,  1.81984952,  2.05505664,
               0.0196817 ,  0.83917525],
             [ 0.52867772,  1.4634736 ,  0.08915141,  1.18414587,  0.72771719,
               2.43476818,  1.53290755,  0.217224  ,  2.27213239,  0.06290109,
               0.04528394,  2.57898919],
             [ 2.6307514 ,  1.49545031,  0.5792385 ,  2.12036343,  1.17591302,
               0.42129971,  0.56339094,  0.86532054,  0.72177407,  1.97292419,
               0.83485538,  1.08703999],
             [ 1.69209656,  2.72318919,  2.48538839,  2.97032829,  0.06787846,
               1.037024  ,  1.97725399,  1.03979296,  2.61054339,  0.47312643,
               0.32169324,  1.38396588],
             [ 2.0940399 ,  1.30867842,  1.70374316,  1.32904259,  2.91124343,
               0.07347759,  2.60358661,  0.69371092,  1.4025634 ,  2.32338829,
               2.91088906,  0.91579748]]),
      np.array([[ 1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.]])),
     (np.array([[ 3.26560029]]),
      3.3783266024307217,
      np.array([[ 0.68028634,  0.47536644,  0.40820536,  0.5065777 ,  0.57677893,
               0.19296128,  0.0373546 ,  0.33223841,  0.78571688,  0.20086868,
               0.56641124,  0.02091999,  0.28895048,  0.05505587,  0.39339425,
               0.21732227,  0.87787964,  0.03211217,  0.53581854]]),
      np.array([[ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,
               1.,  1.,  1.,  1.,  1.,  1.]])),
     (np.array([[ 0.00982413]]),
      -2.5909427897577775,
      np.array([[ 3.25532949]]),
      np.array([[ 0.]])),
     (np.array([[ 2.49231187],
             [ 0.90261213],
             [ 3.73288738]]),
      6.879230337539482,
      np.array([[ 1.60049388,  1.35856355,  1.09958807,  0.48805953,  1.05636965,
               1.58292311,  1.32585452,  1.73855007,  2.54925412,  2.6681989 ,
               2.74368903,  0.16750145,  1.02545294,  2.97664947,  0.59227403,
               1.12936141,  1.27880765],
             [ 0.68054027,  2.22125073,  1.28793262,  0.31770443,  0.86349656,
               0.74482615,  1.69306061,  0.10887424,  2.28939018,  1.22369602,
               2.73761527,  1.67793944,  0.63579084,  0.31465301,  0.43075468,
               1.07400719,  0.21840702],
             [ 2.28426603,  2.54428189,  0.97709985,  0.83146731,  0.71600713,
               2.12958795,  2.60108188,  2.19336796,  1.5935891 ,  1.31059168,
               1.87714577,  0.70445022,  2.29815875,  2.93145966,  2.45851518,
               0.57996003,  1.62175868]]),
      np.array([[ 1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  1.]])),
     (np.array([[ 0.23744389],
             [ 2.66923162]]),
      0.15854451684232096,
      np.array([[ 1.04648488,  2.83687014,  0.22091381,  4.87790512,  5.15138752,
               0.7623651 ,  0.11090703,  3.08557977,  3.18882192,  1.1112289 ,
               5.59462467],
             [ 4.70458985,  4.85266623,  1.42744135,  4.9396991 ,  0.01198469,
               5.49654058,  3.49356221,  1.8350681 ,  4.28425689,  4.39260002,
               4.6053759 ]]),
      np.array([[ 0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.]])),
     (np.array([[ 4.84662271],
             [ 2.48604917]]),
      -8.607346714961416,
      np.array([[ 2.21004028,  5.10231191,  4.93713962,  4.72965614,  6.75687196,
               2.60154637,  6.94972798,  4.77785717,  7.324282  ],
             [ 7.14725998,  3.19357702,  2.56474119,  3.31848722,  1.31536751,
               6.98803349,  5.37540606,  7.44773347,  4.89270677]]),
      np.array([[ 1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.]])),
     (np.array([[ 8.75644456],
             [ 9.14843089]]),
      2.397410585436827,
      np.array([[ 6.81024044,  5.41804509,  1.67016704,  5.41130823,  2.96066901,
               0.31961368,  3.25887757,  5.20149228,  2.42444693,  6.40809972,
               3.85142825,  3.38896917,  6.27081124,  0.54018931,  7.77462336,
               0.20655481,  6.59012767,  2.10773391],
             [ 3.11245739,  6.81728192,  6.8847784 ,  4.06958545,  7.2858601 ,
               3.55160359,  6.23868471,  7.86139836,  6.52003233,  1.6038633 ,
               3.75786396,  2.16325085,  1.38427699,  7.92234283,  2.08013187,
               7.07748777,  4.50559412,  1.26461614]]),
      np.array([[ 1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,
               1.,  0.,  1.,  1.,  1.]])),
     (np.array([[ 0.237812  ],
             [ 0.47359954],
             [ 0.53421666],
             [ 0.82710381]]),
      -5.3756707064322296,
      np.array([[  1.59791399e+00,   6.37825747e-01,   2.85594493e+00,
                2.46204561e+00,   1.78987374e+00,   1.66875099e+00,
                1.41149750e+00,   2.36269333e+00,   1.94707628e+00,
                3.04257604e+00,   2.49490971e+00,   1.42775261e+00,
                2.49810759e+00,   1.91613357e+00,   3.29768177e+00,
                3.89281796e+00,   3.69681024e+00,   3.40717706e+00],
             [  2.22453752e+00,   1.47984880e+00,   3.75223266e+00,
                2.49445942e+00,   2.74521949e+00,   1.18723384e+00,
                1.08173190e+00,   1.26213080e+00,   2.89933870e+00,
                1.90016776e+00,   6.64737600e-01,   2.53003764e+00,
                3.32649333e+00,   2.47883367e+00,   3.55503287e+00,
                1.42749880e+00,   3.05299614e+00,   4.73000377e-02],
             [  8.81305024e-01,   2.19785062e+00,   2.36021397e+00,
                1.85779941e+00,   8.71930025e-01,   1.53769225e+00,
                2.74720042e+00,   3.71535441e+00,   1.75682737e+00,
                2.74964386e-01,   1.91655520e+00,   1.82176121e+00,
                9.40453179e-01,   3.18641157e+00,   2.37124999e-01,
                2.69434178e+00,   2.31348538e+00,   2.78730624e+00],
             [  2.92004599e+00,   4.32224952e-01,   2.47646863e+00,
                2.26249789e+00,   1.05262474e+00,   1.94222117e+00,
                1.29825936e+00,   3.39836963e+00,   2.68113351e+00,
                1.31794528e+00,   1.84633902e-01,   1.45277953e+00,
                2.65309977e-03,   1.33222884e+00,   1.60016935e+00,
                3.90057592e+00,   1.92725145e+00,   2.72848285e+00]]),
      np.array([[ 1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  1.,  0.]])),
     (np.array([[ 0.06595244]]),
      -1.626250650032702,
      np.array([[ 3.88095858,  1.81523379,  2.38225712,  2.8583802 ,  4.03066063,
               4.54360876,  4.2609518 ,  4.1248972 ,  4.97568098,  3.28747156,
               3.26847053,  0.99203543,  0.78529315,  4.9337328 ,  3.7010071 ,
               2.78608978,  0.48100978,  1.86722364]]),
      np.array([[ 0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,
               1.,  0.,  1.,  0.,  1.]])),
     (np.array([[ 1.67359335],
             [ 3.81840948],
             [ 2.31151092],
             [ 2.64249795],
             [ 2.92031828]]),
      -4.044331483025044,
      np.array([[ 2.45730491,  2.08999512,  2.98199899,  1.10589914,  2.36570174,
               2.48310503,  2.25051025,  2.52304526,  1.75041695,  2.61420418,
               1.54152094,  1.09168475,  2.9308714 ,  2.89430337,  2.69899214,
               2.4951992 ,  2.35106091,  0.14681582,  0.93683875,  1.47020719],
             [ 1.74292765,  1.17371972,  2.58027861,  2.93959637,  0.98434858,
               2.41175479,  0.78941665,  1.28911166,  1.08542725,  0.22049081,
               0.04797752,  1.28558864,  2.74508142,  1.83192667,  0.2703349 ,
               2.03254133,  0.09261064,  1.14475657,  1.03536031,  2.77151228],
             [ 1.58014649,  1.27121889,  2.32628094,  2.67320958,  2.98203263,
               0.00468814,  2.3613562 ,  2.88491127,  0.20357247,  2.37189924,
               1.47352383,  2.45351589,  0.4472298 ,  1.71661337,  1.97040473,
               0.21422595,  1.96110022,  0.80898681,  0.06142602,  1.92341402],
             [ 1.45878515,  1.90567354,  1.48924623,  0.87130262,  2.54565189,
               2.03957961,  0.71434625,  1.50204531,  0.82328648,  2.09859867,
               1.55920215,  2.94957463,  2.88189807,  1.47067746,  2.86593025,
               0.12391454,  1.8831459 ,  0.73112402,  0.40081428,  2.41311476],
             [ 2.54676834,  1.18955766,  1.03594131,  1.33828681,  2.13537721,
               0.09885109,  0.8478826 ,  2.86329287,  0.68707373,  1.84998644,
               1.0181972 ,  0.87801463,  0.80328565,  1.20000673,  1.41965514,
               2.05548203,  2.51318858,  2.61116241,  0.48835568,  0.05539466]]),
      np.array([[ 0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,
               1.,  0.,  0.,  0.,  1.,  1.,  1.]]))]

    expected_outputs = [({'w': np.array([[ 0.84423413],
              [ 8.0018003 ],
              [ 0.88544497],
              [ 2.66160753],
              [ 3.82514784]]), 'b': 8.8943026084772292},
      {'dw': np.array([[ 0.25490796],
              [ 0.36818935],
              [ 0.25791583],
              [ 0.57386676],
              [ 0.49306984]]), 'db': 0.33333332959465328},
      [np.nan]),
     ({'w': np.array([[ 3.25463604]]), 'b': 3.3511073331603045},
      {'dw': np.array([[ 0.12178598]]), 'db': 0.30226198142210753},
      [1.4870050835296789]),
     ({'w': np.array([[-0.0105853]]), 'b': -2.5972123334731072},
      {'dw': np.array([[ 0.21996501]]), 'db': 0.067570735479588362},
      [0.074536830737844825]),
     ({'w': np.array([[ 2.43386054],
              [ 0.85089159],
              [ 3.66048549]]), 'b': 6.8368775497282073},
      {'dw': np.array([[ 0.64945912],
              [ 0.57467254],
              [ 0.80446537]]), 'db': 0.47058639155046855},
      [8.377635256801117]),
     ({'w': np.array([[ 0.12010854],
              [ 2.50093907]]), 'b': 0.10351124788091468},
      {'dw': np.array([[ 1.27629836],
              [ 1.86919395]]), 'db': 0.60583612502575268},
      [5.461274238116423]),
     ({'w': np.array([[ 4.63460746],
              [ 2.33958588]]), 'b': -8.6473467148851739},
      {'dw': np.array([[ 2.35572498],
              [ 1.62736992]]), 'db': 0.44444444289815888},
      [np.nan]),
     ({'w': np.array([[ 8.59840123],
              [ 8.94869058]]), 'b': 2.3574105854368268},
      {'dw': np.array([[ 1.75603699],
              [ 2.21933682]]), 'db': 0.44444444444444359},
      [np.nan]),
     ({'w': np.array([[ 0.24868028],
              [ 0.49055936],
              [ 0.55134661],
              [ 0.82485517]]), 'b': -5.3657201142725786},
      {'dw': np.array([[-0.10193258],
              [-0.17146845],
              [-0.17462381],
              [ 0.04115067]]), 'db': -0.10330443266321082},
      [0.8733542099975572]),
     ({'w': np.array([[ 0.16081244]]), 'b': -1.6010007907877144},
      {'dw': np.array([[-0.96089241]]), 'db': -0.25536946640251196},
      [0.91329173570467936]),
     ({'w': np.array([[ 1.56533008],
              [ 3.75942275],
              [ 2.23241623],
              [ 2.55162343],
              [ 2.84643867]]), 'b': -4.0892451755736587},
      {'dw': np.array([[ 1.2027993 ],
              [ 0.65527684],
              [ 0.87881851],
              [ 1.00966102],
              [ 0.82081969]]), 'db': 0.49891290515754583},
      [9.5993035061260681])]
    return test_inputs, expected_outputs
